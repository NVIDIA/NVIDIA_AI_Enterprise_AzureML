FROM nvcr.io/nvidian/nemo-llm/nemollm-inference-trt-only:24.02.rc2
EXPOSE 8000
ADD scripts/auxiliary_files/convert_and_deploy_model.sh /tmp/convert_and_deploy_model.sh
ADD scripts/auxiliary_files/Nemotron-3-8B-Chat-SteerLM.yml /tmp/Nemotron-3-8B-Chat-SteerLM.yml
ADD scripts/auxiliary_files/Nemotron-3-8B-Base-4k.yml /tmp/Nemotron-3-8B-Base-4k.yml
ADD scripts/auxiliary_files/Nemotron-3-8B-Chat-RLHF.yml /tmp/Nemotron-3-8B-Chat-RLHF.yml
ADD scripts/auxiliary_files/Nemotron-3-8B-Chat-SFT.yml /tmp/Nemotron-3-8B-Chat-SFT.yml
ADD scripts/auxiliary_files/Nemotron-3-8B-QA-4k.yml /tmp/Nemotron-3-8B-QA-4k.yml
CMD /tmp/convert_and_deploy_model.sh ${AZUREML_MODEL_DIR}